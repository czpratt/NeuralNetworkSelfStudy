{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a8156e",
   "metadata": {},
   "source": [
    "Training a simple neural network, with PyTorch data loading: https://github.com/jax-ml/jax/blob/main/docs/notebooks/Neural_Network_and_Data_Loading.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b90214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c4bd8e",
   "metadata": {},
   "source": [
    "I am noticing that this is basically the same as the blog post. The blog post has more words. And more examples. So, we can reference that one later if we need more fundamental examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b68719",
   "metadata": {},
   "source": [
    "Let's build a simple MLP without Flax for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f6c81c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m, n, k: 784, 512, Array((), dtype=key<fry>) overlaying:\n",
      "[1797259609 2579123966]\n",
      "m, n, k: 512, 512, Array((), dtype=key<fry>) overlaying:\n",
      "[ 928981903 3453687069]\n",
      "m, n, k: 512, 10, Array((), dtype=key<fry>) overlaying:\n",
      "[4146024105 2718843009]\n"
     ]
    }
   ],
   "source": [
    "def random_layer_params(m, n, key, scale=1e-2):\n",
    "    # split the keys\n",
    "    w_key, b_key = random.split(key)\n",
    "    w = scale * random.normal(w_key, (n, m))\n",
    "    b = scale * random.normal(b_key, (n,))\n",
    "    return w, b\n",
    "\n",
    "def init_network_params(sizes, key):\n",
    "    # obtain all keys\n",
    "    keys = random.split(key, len(sizes))\n",
    "    MLP = []\n",
    "    for m, n, k in zip(sizes[:-1], sizes[1:], keys):\n",
    "        print(f'm, n, k: {m}, {n}, {k}')\n",
    "        MLP.append(random_layer_params(m, n, k))\n",
    "    #MLP = [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "    return MLP\n",
    "\n",
    "layer_sizes = [28*28, 512, 512, 10]\n",
    "step_size = 0.01\n",
    "num_epochs = 8\n",
    "batch_size = 128\n",
    "n_targets = 10\n",
    "# initialize the model's parameters\n",
    "params = init_network_params(layer_sizes, random.key(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1caf04d",
   "metadata": {},
   "source": [
    "784 inputs gets embedded into 512 dimensions, then passes through a linear layer, then gets further embedded (activated) into a 10 dimensional output, which corresponds to our MNIST digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe9a46f",
   "metadata": {},
   "source": [
    "Now let's define our prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "224d7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "def ReLU(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def predict(params, image):\n",
    "    ''' Predict the image based on model params '''\n",
    "    # let initial activations in the image\n",
    "    activations = image\n",
    "    # pass the image through the model\n",
    "    for w, b in params[:-1]:\n",
    "        outputs = jnp.dot(w, activations) + b\n",
    "        activations = ReLU(outputs)\n",
    "    \n",
    "    # from the final weights and params\n",
    "    final_w, final_b = params[-1]\n",
    "    \n",
    "    # obtain the logits\n",
    "    logits = jnp.dot(final_w, activations) + final_b\n",
    "    \n",
    "    # predictions are made from log softmax\n",
    "    return logits - logsumexp(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30001fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-2.2909994, -2.2938476, -2.2901456, -2.3175743, -2.3124409,\n",
       "       -2.3007157, -2.302447 , -2.3278596, -2.2889743, -2.301602 ],      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have the model guess some random flattened image\n",
    "random_flattened_image = random.normal(random.key(1), (28 * 28,))\n",
    "predict(params, random_flattened_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328afeb7",
   "metadata": {},
   "source": [
    "So the model doesn't really have a solid prediction, since all of them look the same.\n",
    "\n",
    "This was just for one batch; let's use vmap so that we can apply this across all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f1ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_predict = vmap(predict, in_axes=(None, 0), out_axes=0)\n",
    " # create 10 batches of 28*28 images for vmap\n",
    "random_flattened_images = random.normal(random.key(1), shape=(10, 28*28))\n",
    "batched_preds = batched_predict(params, random_flattened_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0751833",
   "metadata": {},
   "source": [
    "Now let's use grad to take the derivative of the loss in order to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587b072",
   "metadata": {},
   "source": [
    "First define utility and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89ded03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    ''' \n",
    "    Create a one-hot encording of input x of size k \n",
    "    \n",
    "    --- makes a row of length k, and encodes a 1 if the element matches the index \n",
    "        as we're iterating over the length k, and 0 otherwise.\n",
    "        \n",
    "        # Example one-hot vector: \n",
    "        # inp = jnp.array([2, 0, 1, 6, 2]); one_hot(inp, len(inp))\n",
    "    '''\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "\n",
    "def accuracy(params, images, targets):\n",
    "    ''' Evaluates accurary of model predictions '''\n",
    "    # plucks out the target, which I think should be a one-hot\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    \n",
    "    # pluck out the predicted number for each batch\n",
    "    predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
    "    \n",
    "    # get the average across all the batches as to whether\n",
    "    # we made the right prediction or not\n",
    "    return jnp.mean(predicted_class == target_class)\n",
    "\n",
    "\n",
    "def loss(params, images, targets):\n",
    "    # batched predict gets the log-softmax\n",
    "    # so here we're going to average over them\n",
    "    preds = batched_predict(params, images) # \n",
    "    print(f'batched predictions shape: {preds.shape}') # 128, 10 = (b, nimages)\n",
    "    print(f'targets shape: {targets.shape}') # (128, 10) = same as preds\n",
    "    print(f'targets[0]: {targets.shape}')\n",
    "    \n",
    "    # This is how you get the cross entropy loss, which happens when the \n",
    "    # targets are one-hot encoded (which they are indeed)\n",
    "    # and my predictions are log-softmax outputs\n",
    "    # this obtains the probability of that target, which is in preds. \n",
    "    # remember that preds contains all predictions about all of the digits \n",
    "    # what we are going to optimize / train our network to do is get the highest\n",
    "    # probability which corresponds to each target element, which is one hot encoded\n",
    "    # in the targets vector\n",
    "    return -jnp.mean(preds * targets)\n",
    "\n",
    "\n",
    "# update the model's parameters\n",
    "@jit\n",
    "def update(params, x, y):\n",
    "    grads = grad(loss)(params, x, y)\n",
    "    return [(w - step_size * dw, b - step_size * db)\n",
    "          for (w, b), (dw, db) in zip(params, grads)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04881a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jax.tree_util import tree_map\n",
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "def numpy_collate(batch):\n",
    "    '''\n",
    "    Collate function specifies how to combine a list of data samples into a batch.\n",
    "    default_collate creates pytorch tensors, then tree_map converts them into numpy arrays.\n",
    "    '''\n",
    "    return tree_map(np.asarray, default_collate(batch))\n",
    "\n",
    "def flatten_and_cast(pic):\n",
    "    ''' Convert PIL image to flat (1-dimensional) numpy array.'''\n",
    "    return np.ravel(np.array(pic, dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "097b8175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our dataset, using torch datasets\n",
    "mnist_dataset = MNIST('/tmp/mnist/', \n",
    "                      download=True, \n",
    "                      transform=flatten_and_cast)\n",
    "\n",
    "# Create pytorch data loader with custom collate function\n",
    "training_generator = DataLoader(mnist_dataset, \n",
    "                                batch_size=batch_size, \n",
    "                                collate_fn=numpy_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0562911f",
   "metadata": {},
   "source": [
    "Now let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5cde99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full train dataset (for checking accuracy while training)\n",
    "train_images = np.array(mnist_dataset.train_data).reshape(len(mnist_dataset.train_data), -1)\n",
    "train_labels = one_hot(np.array(mnist_dataset.train_labels), n_targets)\n",
    "\n",
    "# Get full test dataset\n",
    "mnist_dataset_test = MNIST('/tmp/mnist/', download=True, train=False)\n",
    "test_images = jnp.array(mnist_dataset_test.test_data.numpy().reshape(len(mnist_dataset_test.test_data), -1), dtype=jnp.float32)\n",
    "test_labels = one_hot(np.array(mnist_dataset_test.test_labels), n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50da9b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batched predictions shape: (128, 10)\n",
      "targets shape: (128, 10)\n",
      "targets[0]: (128, 10)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      4\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m training_generator:\n\u001b[1;32m      7\u001b[0m         y \u001b[38;5;241m=\u001b[39m one_hot(y, n_targets)\n\u001b[1;32m      8\u001b[0m         params \u001b[38;5;241m=\u001b[39m update(params, x, y)\n",
      "File \u001b[0;32m~/py/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/py/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/py/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/py/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/py/lib/python3.10/site-packages/torchvision/datasets/mnist.py:131\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    127\u001b[0m     targets \u001b[38;5;241m=\u001b[39m read_label_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_folder, label_file))\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data, targets\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is index of the target class.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for x, y in training_generator:\n",
    "        y = one_hot(y, n_targets)\n",
    "        params = update(params, x, y)\n",
    "        \n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    train_acc = accuracy(params, train_images, train_labels)\n",
    "    test_acc = accuracy(params, test_images, test_labels)\n",
    "    \n",
    "    print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "    print(\"Training set accuracy {}\".format(train_acc))\n",
    "    print(\"Test set accuracy {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2745c185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585d9bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231714b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
